CRACK TIPS:
** is this necessary? can simple refinement solve the problem for all practical cases? maybe move to long-term 
** crack tip elements may require creating a basis structure
** acceptance test: high accuracy crack tip stress intensity factor (crack-tip elements)


- Three-dimensional variations in material poperties. Two ways to implement:
-- Multiple subdomains with boundaries. Simpler when the elastic structure has a small number of components
-- Smooth volumetric variations -- treat this as a body force and integrate volumetrically. Possibly simpler when the elastic structure is very complex.


- Linear viscoelasticity. Two possible ways to implement:
-- Correspondence priniciple
--- how many different elastic problems does an inverse Laplace transform code require to handle on
-- Body forces 
--- more general, could be applied to plasticity or dynamic wave propagation, 
--- more difficult to code


- Stokes flow example.
-- Requires nothing that isn't already implemented!
-- For kernels: http://en.wikipedia.org/wiki/Stokes_flow#By_Green.27s_function:_the_Stokeslet
-- also: http://www.fuw.edu.pl/~mklis/publications/Hydro/oseen.pdf


- Methods for solving the inverse problem. Many many different ways of posing the problem. 


- A tool for determining memory requirements and approximate run times for a given set of input files. Runs a simple problem to benchmark the current machine's capabilities and then extrapolates to whatever the problem is.


- Simple adaptive meshing! probably relatively low cost to implement, very high value!
-- One of the primary difficulties in traditional FEM is hanging nodes. I intend to handle hanging nodes anyway because meshing is much more difficult if they are forbidden.
-- Remaining difficulty is to find a good error estimator. 
-- Use the formulation from the "SGBEM" book.


- Higher order bases? is this worth the effort? medium-high cost, what is the value? be realistic.
-- Useful for crack-tip elements.
-- Could at least move the stray basis and interpolation code into one place.
-- And set up some type of dof map structure.
-- Probably not useful for static elastic problems. Adaptive meshing would be more useful. 
-- Key problem is that the surface shape has to be parameterized to the same accuracy as the field of interest, otherwise the 
-- I suspect higher order would be very useful for volumetric problems/body forces, where surface shape does not need to be parameterized so heavily.
-- I'm not convinced it would be that difficult once a better DOF handling solution is in place. 


- Faster near-field matrix construction? Once FMM-BEM integration is implemented, this will be the main bottleneck for solving large problems.
-- Using vector instructions is difficult because it reduces portability and breaks standard design barrier, interface should be agnostic to implementation.
-- try the nearly singular tri rule = http://www98.griffith.edu.au/dspace/bitstream/handle/10072/54329/86520_1.pdf?sequence=1
-- Templating (mako, titen, etc) based solution for code generation of highly efficient core chunks of code? 
--- think about this more, write a note, positives? negatives? cost?
--- http://szelei.me/code-generator/
--- http://eli.thegreenplace.net/2011/07/03/parsing-c-in-python-with-clang/

- Think about whether the direct treecode inversion algorithm is worthwhile
-- Avoids any problems with preconditioning while allowing the solution of large
   BEM problems... 
-- Going to be a tough route. Lots of code. Hard to parallelize. Super intense stuff...
-- Precompute the DAG of FMM/direct inversion operations -- this will allow simple, but powerful  and scalable parallelism -- look at starpu for a runtime system

- see how FMM accuracy changes as a function of
    1) radius of equivalent surface
    2) radius of check surface
    3) order of expansion
    4) multipole acceptance criteria

CAPACITY TESTING/BUILD TESTING:
** turn the mac mini into a jenkins build server, put it in a VM or docker container, see what packages are required (in ubuntu)
** test with python3, use tox to run acceptance tests on a variety of platforms
** do capacity testing by comparing the ratio with a simple matrix-multiply test case as a benchmark of the raw computational performance of a given machine.
** capacity test: benchmark the fmm
** capacity test: time to perform 3D nearfield integration
** capacity test: solve a laplace problem
** capacity test: reuse the adaptively refined okada problem, but time it, realistic!
** a compilation time test -- a recompile using ccache should take < 2 seconds? also would like a compilation time test for the initial compile -- under 20 seconds would be nice
** compilation timing code is in tbempy/setup.py indicating which files take longer to compile
