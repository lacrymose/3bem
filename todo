CURRENT: 
** acceptance test: setup fmm operators for python wrapper, solve a large problem in 2D and confirm (log)linear time cost with refinement

NEXT: hanging nodes 
** acceptance test #1: fault intersecting surface not at point
** acceptance test #2: adaptively refined okada solution (using the real error as the refinement criterion, so not technically adaptive meshing yet)
** Handle when fault-surface intersection does not occur at a vertex.

KERNEL OVERHAUL
** move obs, src loop into the kernel functions which will reduce the number of function calls and also allow sse/avx implementations of those kernel functions
** if a large number of obs and src points are passed to the kernel functions simultaneously, then maybe the output can simply be a vector rather than using the templated tensor arrays
** remove the templating on kernel tensor shape in favor of returning a large double array from a kernel function called with a bunch of inputs simultaneously
** faster (AVX, GPU) kernel implementations + capacity test

INTEGRATION:
** acceptance test: 3D problem with sinh-sigmoidal quadrature
** try other nearly-singular quadrature methods (not sinh-sigmoidal)

MISC:
** characterize the sinh-sigmoidal method
** use iterators for traversing point sets?
** characterize the galerkin BEM for hypersingular kernels
** split out the fmm scheduler/traversal
** create a continuity builder struct, move continuity builder stuff to cpp file
** BUILTIN_FLOAT_DTYPE(16) in boost_numpy fails on odyssey
** automated testing tools against pdetool? -- probably excessive

CAPACITY TESTING/BUILD TESTING:
** automated build testing on mac, ubuntu, with clang, gcc, intel compilers -- maybe turn the mac mini into a build server
http://www.joelonsoftware.com/articles/fog0000000023.html
** test the build system on a fresh ubuntu (just use a docker container)
** test with python3
** some simple capacity tests. how to make sure these run in the same conditions? remove timings from standard unit tests
** capacity test: benchmark the fmm
** capacity test: time to perform 3D nearfield integration
** capacity test: solve a laplace problem
** capacity test: reuse the adaptively refined okada problem, but time it, realistic!
** need a compilation time test -- a recompile using ccache should take < 2 seconds? this poses the same hardware-specific capacity testing issues as the speed stuff. also would like a compilation time test for the initial compile -- under 20 seconds would be nice
** one solution to the capacity testing issue is to enforce that new versions should run faster than old versions or to provide specific git revisions that are benchmarks for a given capacity. this could result in a long capacity test, but
** compilation timing code is in tbempy/setup.py indicating which files take longer to compile
